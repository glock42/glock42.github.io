<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>为什么机器学习真的可以学到东西？ | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言开始跟《机器学习基石》这门课，相对于Stanford那门课，这门明显难度大很多，我跟到第10个Lecture，才刚刚讲到Logistic Regression。前面费了很大力气在讲机器什么时候可以学习，以及证明为什么能学习。 此文主要是基于《机器学习基石》的学习笔记。Topic是为什么机器可以学习？ 机器学习流程下面是一个粗略的机器学习流程图  机器学习最开始也是最终的目的是获得一个targe">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="为什么机器学习真的可以学到东西？">
<meta property="og:url" content="http://yoursite.com/2016/07/27/为什么机器可以学习？/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="前言开始跟《机器学习基石》这门课，相对于Stanford那门课，这门明显难度大很多，我跟到第10个Lecture，才刚刚讲到Logistic Regression。前面费了很大力气在讲机器什么时候可以学习，以及证明为什么能学习。 此文主要是基于《机器学习基石》的学习笔记。Topic是为什么机器可以学习？ 机器学习流程下面是一个粗略的机器学习流程图  机器学习最开始也是最终的目的是获得一个targe">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://beader.me/mlnotebook/section2/images/basic_setup_of_the%20_learning_problem.png">
<meta property="og:image" content="http://beader.me/mlnotebook/section2/images/bin_sample.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot.png">
<meta property="og:image" content="http://beader.me/mlnotebook/section2/images/hypothesis_overlap.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot1.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot22.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/ssss.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/okkkkkkk.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/vvvvvv.png">
<meta property="og:updated_time" content="2018-04-15T14:49:01.369Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="为什么机器学习真的可以学到东西？">
<meta name="twitter:description" content="前言开始跟《机器学习基石》这门课，相对于Stanford那门课，这门明显难度大很多，我跟到第10个Lecture，才刚刚讲到Logistic Regression。前面费了很大力气在讲机器什么时候可以学习，以及证明为什么能学习。 此文主要是基于《机器学习基石》的学习笔记。Topic是为什么机器可以学习？ 机器学习流程下面是一个粗略的机器学习流程图  机器学习最开始也是最终的目的是获得一个targe">
<meta name="twitter:image" content="http://beader.me/mlnotebook/section2/images/basic_setup_of_the%20_learning_problem.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-为什么机器可以学习？" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/27/为什么机器可以学习？/" class="article-date">
  <time datetime="2016-07-26T17:15:06.000Z" itemprop="datePublished">2016-07-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      为什么机器学习真的可以学到东西？
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>开始跟《机器学习基石》这门课，相对于<code>Stanford</code>那门课，这门明显难度大很多，我跟到第10个<code>Lecture</code>，才刚刚讲到<code>Logistic Regression</code>。前面费了很大力气在讲机器什么时候可以学习，以及证明为什么能学习。</p>
<p>此文主要是基于《机器学习基石》的学习笔记。<code>Topic</code>是为什么机器可以学习？</p>
<h2 id="机器学习流程"><a href="#机器学习流程" class="headerlink" title="机器学习流程"></a>机器学习流程</h2><p>下面是一个粗略的机器学习流程图</p>
<p><img src="http://beader.me/mlnotebook/section2/images/basic_setup_of_the%20_learning_problem.png" alt=""></p>
<p>机器学习最开始也是最终的目的是获得一个<code>target function</code>，喂进去数据能直接得到正确结论的函数。为了得到这个函数，我们需要一大堆的训练数据。然后通过一个好的机器学习算法，从一大堆<code>可能的function(也就是H)</code>中挑选一个<code>比较好的function(也就是g)</code>，这个<code>g</code>和<code>target function</code>长得越像越好。<br><a id="more"></a></p>
<h2 id="Hoeffding’s-inequality"><a href="#Hoeffding’s-inequality" class="headerlink" title="Hoeffding’s inequality"></a>Hoeffding’s inequality</h2><p>大家有没有想过，为什么这样就能学到东西。我们的算法只是在训练数据上跑，从训练数据跑出来的<code>g</code>，我们怎么能确定它也能在测试数据上跑的很好呢？这个就是问题的关键。其实接下来内容主要就是论证这个问题。</p>
<p>先来考虑一个简单的问题。比如说我们现在有一个黑罐子，里面有很多弹珠，只有两种颜色，黄的和绿的。好现在问你，你怎么能知道黄色弹珠大概有多少颗？</p>
<p><img src="http://beader.me/mlnotebook/section2/images/bin_sample.png" alt=""></p>
<p>大家肯定都会说抽样。没错，我们抽出10个弹珠，很容易能知道黄色弹珠在<code>sample</code>中的比例。但是这个比例真的能代表罐子中的比例吗？也许能，也许不能。而且能的记录会随着我们<code>sample</code>数目的增大而增大。但是也有可能你抓出一把全绿。但这种情况发生的记录很小。这里我们有一个定理保证这种偏差发生的记录很小。</p>
<p><code>Hoeffding&#39;s inequality</code>可以保证偏差很大发生的几率很小，并且随着<code>N</code>的增大很减小。公式如下，<code>v</code>代表<code>sample</code>中黄色弹珠的比例，<code>μ</code>表示罐子中黄色弹珠的比例。<code>ϵ</code>也就是偏差。</p>
<blockquote>
<p>ℙ[|ν−μ|&gt;ϵ]≤2exp(−2(ϵ^2)N)</p>
</blockquote>
<h2 id="坏事的发生"><a href="#坏事的发生" class="headerlink" title="坏事的发生"></a>坏事的发生</h2><p>现在我们称<code>v</code>为<code>Ein</code>,<code>μ</code>为<code>Eout</code>，现在我们已经证明了<code>Ein</code>和<code>Eout</code>不会差的太远，更重要的事情是保重<code>Ein</code>越小越好，这就需要一个好的算法。<br>还记得上面的学习流程吗，我们的算法是从很多个<code>h</code>中去挑选一个<code>Ein</code>最小的<code>h</code>让它成为<code>g</code>。但是这里会有坏事情发生。<br>所谓的坏事情就是<code>bad sample</code>，就是说我们抽出了十个全是绿的弹珠。现在有一个好的<code>h</code>称之为<code>h1</code>，和坏的<code>h</code>叫<code>h2</code>，<code>h1</code>对于这个<code>bad sample</code>的表现当然是糟糕的，而恰好<code>h2</code>表现很好，那<code>h2</code>就被选成<code>g</code>了。</p>
<p>当出现坏事的时候，我们学习就会困难，可以直接说不能学习。所以这个坏事出现的概率是多少呢？把所有h中发生坏事的几率加起来。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot.png" alt=""></p>
<p>从上图的式子中可以看到，坏事发生的几率和<code>M</code>有关。<code>M</code>也就是<code>h</code>的个数。<br>从现在的条件来看，如果<code>M</code>很大甚至无线的话那么<code>Learning</code>是不可行的。</p>
<h3 id="无效的Hypothesis"><a href="#无效的Hypothesis" class="headerlink" title="无效的Hypothesis"></a>无效的Hypothesis</h3><p>真实的情况是<code>M</code>一般不会很大，请再仔细看看上一张图的推导，<code>M</code>是通过把所有的<code>h</code>坏事发生的概率加起来的，但是其实这些<code>h</code>不是互相独立的。所以这些<code>h</code>是有重复的，如下图。</p>
<p><img src="http://beader.me/mlnotebook/section2/images/hypothesis_overlap.png" alt=""></p>
<p>比如说，我们想学习的<code>target function</code>是一条把<code>x1</code>分类成正负的线。现在<code>h</code>就有无数个，因为任意一条线都能分类，但是实际有意义的只有两种，分成正的和负的。<br>如果是两个点的话，实际有效的<code>h</code>就有4种，但是3个点就有可能不到8种了，因为会出现三点共线的情况。4个点的话按理说有16种，但是同样有一种情况不会发生，请看下图。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot1.png" alt=""></p>
<p>所以现在我们的公式就变成了这样，大大减小<code>M</code>的个数</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/Screenshot22.png" alt=""></p>
<h2 id="成长函数的上限"><a href="#成长函数的上限" class="headerlink" title="成长函数的上限"></a>成长函数的上限</h2><p>现在我们给上面<code>effective(N)</code>一个称呼，叫做成长函数。也就是说，对于某一个输入<code>D</code>，<code>H</code>最多能够产生的多少种方程。注意是种类的数量。<br>这个所谓的种类我们也给一个定义叫做<code>dichotomy</code>,用来表示<code>H</code>对与<code>D</code>的二元分类情况。<br>好，现在问题的关键，就是<code>H</code>到底能把<code>D</code>分成多少个<code>dichotomy</code>。也就是它的成长函数到底是多少？<br>但是我们很难确定它的成长函数。但是好在我们拥有一个叫做<code>break point</code>的东西，这就是成长函数的上限。我们再看回上面分类的例子。</p>
<ol>
<li>一个点能分成两种</li>
<li>两个点分成四种</li>
<li>三个点分成六种或者八种</li>
<li>四个点只有14种(<code>break point</code>)</li>
</ol>
<p>这里的输入为三个点就是一个<code>break point</code>。也就是说当输入N个点，<code>H</code>不能够把这个<code>N</code>个点的排列组合全部表示出来时<code>(2^N)</code>，<code>N</code>就是一个<code>break point</code>。<br>当<code>H</code>能把<code>N</code>的全部组合表示出来时，说明这<code>N</code>个点被<code>H</code>给<code>shatter</code>掉了</p>
<p>我们用<code>B(N,k)</code>来表示当输入<code>N</code>个点时，<code>H</code>可以最多产生多少个<code>dichotomy</code>。<br>通过数学归纳法我们可以证明到</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/ssss.png" alt=""></p>
<h2 id="VC-BOUND"><a href="#VC-BOUND" class="headerlink" title="VC BOUND"></a>VC BOUND</h2><p>现在到了最后一步，除了把上边那个成长函数的上限代入进去之外，还需要进行一系列的变形，这些变形需要很强的数学能力和概率上面的知识，我自己都不太懂，况且我觉得大部分人都不需要了解。这里我就略过，有兴趣的强人自己<code>google</code>咯。<br>最终的式子如下</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/okkkkkkk.png" alt=""></p>
<p>好了，现在我们终于能说机器学习确实可以学到东西了。但是需要满足三个条件。</p>
<ol>
<li>有一个好的<code>H</code>(拥有<code>break point</code>)</li>
<li>足够多的数据</li>
<li>好的算法，能够使<code>Ein</code>足够小</li>
</ol>
<p>这三者的关系如下图。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/vvvvvv.png" alt=""></p>
<p><code>dvc = k - 1</code>，大致上可以把它看出<code>theta</code>的维度加1</p>
<p>上图很清晰的说明，并不是说你的模型搞得很复杂，算法弄得很好，就能学好，反而是取到一个折中的点，这样的学习才最有效。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/27/为什么机器可以学习？/" data-id="cjg0y8s0k000xl35ykrzbaaau" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/07/28/进程与线程/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          进程与线程
        
      </div>
    </a>
  
  
    <a href="/2016/06/25/Tomcat 架构探索/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Tomcat 架构探索</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Network/">Computer Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Database-System/">Database System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed-Computing/">Distributed Computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed-System/">Distributed System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MIT-6-828/">MIT 6.828</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Operating-system/">Operating system</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tomcat/">Tomcat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/杂/">杂</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 20px;">Algorithm</a> <a href="/tags/Android/" style="font-size: 16px;">Android</a> <a href="/tags/Computer-Network/" style="font-size: 10px;">Computer Network</a> <a href="/tags/Database-System/" style="font-size: 10px;">Database System</a> <a href="/tags/Distributed-Computing/" style="font-size: 10px;">Distributed Computing</a> <a href="/tags/Distributed-System/" style="font-size: 10px;">Distributed System</a> <a href="/tags/Java/" style="font-size: 12px;">Java</a> <a href="/tags/MIT-6-828/" style="font-size: 14px;">MIT 6.828</a> <a href="/tags/Machine-Learning/" style="font-size: 12px;">Machine Learning</a> <a href="/tags/Operating-system/" style="font-size: 18px;">Operating system</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/杂/" style="font-size: 10px;">杂</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/06/11/Raft 共识算法/">Raft 共识算法</a>
          </li>
        
          <li>
            <a href="/2016/12/30/数据库事务与并发控制/">数据库事务与并发控制</a>
          </li>
        
          <li>
            <a href="/2016/12/18/计算机网络自顶向下之可靠传输协议的笔记/">计算机网络自顶向下之可靠传输协议的笔记</a>
          </li>
        
          <li>
            <a href="/2016/12/07/MIT 6.828 lab5/">MIT 6.828 lab5</a>
          </li>
        
          <li>
            <a href="/2016/12/02/MIT 6.828 lab4/">MIT 6.828 lab4</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>生成学习算法 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="生成学习算法可能大部分人之前学过的分类算法，都是基于train data来最佳化参数，从而得到data的类别。也就是基于p(y|x; θ)来进行学习，比如Logistic Regression。现在我们换一种思路，反过来求解，分别对p(x|y) 求解，也就是说，对每一个y，model一个概率模型。当需要对新的data分类时，分别计算属于每个类的概率，从而得到最优的类别。公式基于贝叶斯定理,如下所示">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="生成学习算法">
<meta property="og:url" content="http://yoursite.com/2016/10/30/生成学习算法/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="生成学习算法可能大部分人之前学过的分类算法，都是基于train data来最佳化参数，从而得到data的类别。也就是基于p(y|x; θ)来进行学习，比如Logistic Regression。现在我们换一种思路，反过来求解，分别对p(x|y) 求解，也就是说，对每一个y，model一个概率模型。当需要对新的data分类时，分别计算属于每个类的概率，从而得到最优的类别。公式基于贝叶斯定理,如下所示">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-45-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-45-08%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-44-52%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-42-53%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-43-20%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-43-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-31%2020-40-54%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-31%2020-40-44%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
<meta property="og:updated_time" content="2018-04-15T14:49:01.371Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="生成学习算法">
<meta name="twitter:description" content="生成学习算法可能大部分人之前学过的分类算法，都是基于train data来最佳化参数，从而得到data的类别。也就是基于p(y|x; θ)来进行学习，比如Logistic Regression。现在我们换一种思路，反过来求解，分别对p(x|y) 求解，也就是说，对每一个y，model一个概率模型。当需要对新的data分类时，分别计算属于每个类的概率，从而得到最优的类别。公式基于贝叶斯定理,如下所示">
<meta name="twitter:image" content="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-45-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-生成学习算法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/30/生成学习算法/" class="article-date">
  <time datetime="2016-10-30T13:21:06.000Z" itemprop="datePublished">2016-10-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      生成学习算法
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="生成学习算法"><a href="#生成学习算法" class="headerlink" title="生成学习算法"></a>生成学习算法</h2><p>可能大部分人之前学过的分类算法，都是基于<code>train data</code>来最佳化参数，从而得到<code>data</code>的类别。也就是基于<code>p(y|x; θ)</code>来进行学习，比如<code>Logistic Regression</code>。现在我们换一种思路，反过来求解，分别对<code>p(x|y)</code> 求解，也就是说，对每一个<code>y</code>，<code>model</code>一个概率模型。当需要对新的<code>data</code>分类时，分别计算属于每个类的概率，从而得到最优的类别。公式基于贝叶斯定理,如下所示。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-45-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""><br><a id="more"></a></p>
<h2 id="高斯线性判别"><a href="#高斯线性判别" class="headerlink" title="高斯线性判别"></a>高斯线性判别</h2><p>这个算法前提是<code>p(x|y)</code> 是基于多变量正态分布。多变量正态分布模型如下。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-45-08%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>现在因为只有两种情况，<code>y</code>属于伯努利分布，然后分别对两种情况来model 多变量正态分布</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-44-52%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>对所有样本的几率和取对数，进行最大似然估计。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-42-53%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>好，现在我们共有四个参数<code>φ</code>,<code>Σ</code>, <code>μ0</code> ,<code>μ1</code> 。根据上面公式可分别求出四个参数。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-43-20%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>到这里，高斯线性判别已经结束。我们分别对两个类型，进行拟合高斯模型。接下来需要分类的话，只需要对新的<code>data</code>分别用各自的高斯函数求解比较即可。具体的做法如下图。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-29%2023-43-27%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<h3 id="GDA与Logistics回归"><a href="#GDA与Logistics回归" class="headerlink" title="GDA与Logistics回归"></a>GDA与Logistics回归</h3><p>其实正好是一个相反的关系，当我们求解<code>p(y = 1|x;φ,μ0,μ1,Σ)</code>时，便是在求解Logistics回归，我们用上面的公式，并运用贝叶斯公式，即可得到Logistics回归的公式。</p>
<p>那么我们到底应该选用哪种算法？</p>
<p>大部分的情况下，Logistics回归的表现都会比GDA要好。因为GDA对数据分布模型依赖性很强。因为GDA的前提是<code>p(x|y)</code>是多变量正态分布的。当<code>p(x|y)</code>是多变量正态分布时，<code>p(y|x)</code>一定是Logistics回归的表现形式。然而反过来却不一定。也就是说GDA做了一个更强的假设。</p>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>朴素贝叶斯也是属于生成学习算法的一种。既然是属于生成学习算法，那我们的目标只有一个。那就是计算<code>p(y|x)</code>的概率，选取最大的那一类。理论还是和之前一样，使用贝叶斯公式，反过来计算。此处有个问题，若x是多维的应该如何计算。这里有一个强假设，就是说每一个特征的概率与其他概率是不相关的。这就是<code>Naive Bayes (NB) assumption</code>，这在实际生活中，当然是不可能的，但是即使如此，贝叶斯分类的效果依然是很好的。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-31%2020-40-54%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>在上面的公式中，我们其实只有三个参数，我们分别用 <code>φi|y=1 = p(xi=1|y=1)</code>,<code>φi|y=0 = p(xi=1|y=0)</code>和 <code>φy = p(y=1)</code> 来表示。计算公式如下。</p>
<p><img src="http://7xrsib.com1.z0.glb.clouddn.com/2016-10-31%2020-40-44%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>下面给出一维的实现，多维其实一样的，只不过是把每一维都乘起来。粗粗一写，原谅不良的变量名，以及大量复制黏贴。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一维特征情况</span></span><br><span class="line">train_data = [ &#123;<span class="string">'Name'</span>:<span class="string">'Drew'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Claudia'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Drew'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Drew'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Alberto'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Karin'</span>&#125;, </span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Nina'</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'Name'</span>:<span class="string">'Sergio'</span>&#125; ]</span><br><span class="line">train_label = [<span class="string">'Male'</span>,<span class="string">'Female'</span>,<span class="string">'Female'</span>,<span class="string">'Female'</span>,<span class="string">'Male'</span>,<span class="string">'Female'</span>,<span class="string">'Female'</span>,<span class="string">'Male'</span>]</span><br><span class="line">predict_data = [&#123;<span class="string">'Name'</span>:<span class="string">'Drew'</span>&#125;]</span><br><span class="line">predict_label = <span class="keyword">None</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多维特征的情况</span></span><br><span class="line"><span class="comment"># train_data = [ &#123;'Name':'Drew','Over170':'No','Eye':'Blue','Hair':'Short'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Claudia','Over170':'Yes','Eye':'Brown','Hair':'Long'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Drew','Over170':'No','Eye':'Blue','Hair':'Long'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Drew','Over170':'No','Eye':'Blue','Hair':'Long'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Alberto','Over170':'Yes','Eye':'Brown','Hair':'Short'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Karin','Over170':'No','Eye':'Blue','Hair':'Long'&#125;, </span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Nina','Over170':'Yes','Eye':'Brown','Hair':'Short'&#125;,</span></span><br><span class="line"><span class="comment">#         &#123;'Name':'Sergio','Over170':'Yes','Eye':'Blue','Hair':'Long'&#125; ]</span></span><br><span class="line"><span class="comment"># train_label = ['Male','Female','Female','Female','Male','Female','Female','Male']</span></span><br><span class="line"><span class="comment"># predict_data = [&#123;'Name':'Drew','Over170':'Yes','Eye':'Blue','Hair':'Long'&#125;]</span></span><br><span class="line"><span class="comment"># predict_label = None;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X, Y, predicted)</span>:</span></span><br><span class="line">    theta_y1 = <span class="number">0</span> <span class="comment"># φi|y=1</span></span><br><span class="line">    theta_y0 = <span class="number">0</span> <span class="comment"># φi|y=0</span></span><br><span class="line">    theta_y = <span class="number">0</span> <span class="comment"># φy</span></span><br><span class="line"></span><br><span class="line">    t1 = <span class="number">0</span></span><br><span class="line">    t2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</span><br><span class="line">        <span class="keyword">if</span> X[i][<span class="string">'Name'</span>] == predict_data[<span class="number">0</span>][<span class="string">'Name'</span>] <span class="keyword">and</span> Y[i] == predicted:</span><br><span class="line">            t1 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> Y[i] == predicted:</span><br><span class="line">            t2 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    theta_y1 = t1 / t2</span><br><span class="line"></span><br><span class="line">    t1 = <span class="number">0</span></span><br><span class="line">    t2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</span><br><span class="line">        <span class="keyword">if</span> X[i][<span class="string">'Name'</span>] == predict_data[<span class="number">0</span>][<span class="string">'Name'</span>] <span class="keyword">and</span> Y[i] != predicted:</span><br><span class="line">            t1 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> Y[i] != predicted:</span><br><span class="line">            t2 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    theta_y0 = t1 / t2</span><br><span class="line"></span><br><span class="line">    t1 = <span class="number">0</span></span><br><span class="line">    t2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</span><br><span class="line">        <span class="keyword">if</span> Y[i] == predicted:</span><br><span class="line">            t1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    theta_y = t1 / len(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (theta_y1, theta_y0, theta_y)</span><br><span class="line"></span><br><span class="line">theta_y1, theta_y0, theta_y = predict(train_data, train_label, <span class="string">'Male'</span>)</span><br><span class="line"></span><br><span class="line">print(theta_y1 * theta_y / (theta_y1 * theta_y + theta_y0 * (<span class="number">1</span> - theta_y)))</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>CS229</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/30/生成学习算法/" data-id="cjg0y8s0v001fl35yet05jx99" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/11/06/MIT 6.828 lab1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          MIT 6.828 lab1
        
      </div>
    </a>
  
  
    <a href="/2016/10/12/我对于动态规划的理解/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">我对于动态规划的理解</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Network/">Computer Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Database-System/">Database System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed-Computing/">Distributed Computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed-System/">Distributed System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MIT-6-828/">MIT 6.828</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Operating-system/">Operating system</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tomcat/">Tomcat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/杂/">杂</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 20px;">Algorithm</a> <a href="/tags/Android/" style="font-size: 16px;">Android</a> <a href="/tags/Computer-Network/" style="font-size: 10px;">Computer Network</a> <a href="/tags/Database-System/" style="font-size: 10px;">Database System</a> <a href="/tags/Distributed-Computing/" style="font-size: 10px;">Distributed Computing</a> <a href="/tags/Distributed-System/" style="font-size: 10px;">Distributed System</a> <a href="/tags/Java/" style="font-size: 12px;">Java</a> <a href="/tags/MIT-6-828/" style="font-size: 14px;">MIT 6.828</a> <a href="/tags/Machine-Learning/" style="font-size: 12px;">Machine Learning</a> <a href="/tags/Operating-system/" style="font-size: 18px;">Operating system</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/杂/" style="font-size: 10px;">杂</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/06/11/Raft 共识算法/">Raft 共识算法</a>
          </li>
        
          <li>
            <a href="/2016/12/30/数据库事务与并发控制/">数据库事务与并发控制</a>
          </li>
        
          <li>
            <a href="/2016/12/18/计算机网络自顶向下之可靠传输协议的笔记/">计算机网络自顶向下之可靠传输协议的笔记</a>
          </li>
        
          <li>
            <a href="/2016/12/07/MIT 6.828 lab5/">MIT 6.828 lab5</a>
          </li>
        
          <li>
            <a href="/2016/12/02/MIT 6.828 lab4/">MIT 6.828 lab4</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>